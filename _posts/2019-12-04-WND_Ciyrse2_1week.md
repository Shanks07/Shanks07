---
layout: post  #这个不变
title: "吴恩达-深度学习-Course2-改善深层神经网络-第一周测验" #标题
date: 2019-12-04 09:43 #时间
description: "Life is short,You need Python"  #说明
tag: python #这是分类标签
---

# 1.1 训练、验证、测试集
**小数据**（100条、1000条或1万条数据）：将所有数据三七分(70%验证集，30%测试集)，也可按照60%训练，20%验证，20%测试集来划分。

**大数据**（百万级别的数据量）：验证集和测试集占数据总量的比例会趋向于变得更小。
```
eg: 有10,000,000个例子，你会如何划分训练/开发/测试集？
answer: 训练集占98% ， 开发集占1% ， 测试集占1% 。
```

summary:

数据集规模相对较小，适用传统的划分比例。

数据集规模较大的，验证集和测试集要小于数据总量的20%或10%。
____________________________________________________________________
确保验证集和测试集的数据来自同一分布,因为要用验证集来评估不同的模型，尽可能地优化性能，验证集和测试集来自同一分布就会很好。

# 1.3 机器学习基础
初始模型训练完成后，首先要知道算法的偏差高不高，偏差高不高。进行网络参数的对应调整。 训练网络、选择网络或者准备更多的数据。

# 1.4 正则化
解决高方差问题的方法:正则化、准备更多数据。正则化通常有助于避免过度拟合或减少网络误差。

在训练网络时，人们越来越倾向于使用L2正则化。
<div>
  <img src="/images/image/regulation.png" />
</div>
其中：
```
question1：为什么只正则化参数w？而不再加上参数b呢？
answer1: w通常是一个高维参数矢量，已经可以表达高偏差问题，w可能包含有很多参数，我们不可能拟合所有参数，而b只是单个数字，所以w几乎涵盖了所有参数，而不是b，如果加了参数b，没什么影响，因为b只是众多参数中的一个，所以通常省略不计。
```
如果用L1正则化，w最终会是稀疏的，也就是说w向量中有很多0。 虽然L1正则化使得模型变稀疏，却没有降低太多存储内存。

λ是正则化参数，通常使用验证集或交叉验证集来配置这个参数，考虑训练集之间的权衡，把参数设置为较小值，这样可以避免过拟合。

什么是权重衰减？ 答：正则化技术（例如L2正则化）导致梯度下降在每次迭代时权重收缩。

# 1.5 为什么正则化有利于预防过拟合呢？
